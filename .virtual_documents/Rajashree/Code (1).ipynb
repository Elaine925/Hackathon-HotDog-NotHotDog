import os
import shutil

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from tensorflow import keras
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import image_dataset_from_directory
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras import layers



# file_path = '/content/drive/My Drive/path/to/your/file.txt'
# with open(file_path, 'r') as file:
#     content = file.read()
#     print(content)


from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)
val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)


train_ds = image_dataset_from_directory(
    '../hotdog-nothotdog/train',
    labels='inferred',
    label_mode='binary',
    image_size=[128, 128],
    interpolation='nearest',
    batch_size=64,
    shuffle=True,
)
valid_ds = image_dataset_from_directory(
    '../hotdog-nothotdog/test',
    labels='inferred',
    label_mode='binary',
    image_size=[128, 128],
    interpolation='nearest',
    batch_size=64,
    shuffle=True,
)


# Converting data to float
def convert_to_float(image, label):
    image = tf.image.convert_image_dtype(image, dtype=tf.float32)
    return image, label

AUTOTUNE = tf.data.experimental.AUTOTUNE
train_ds = (
    train_ds
    .map(convert_to_float)
    .cache()
    .prefetch(buffer_size=AUTOTUNE)
)
valid_ds = (
    valid_ds
    .map(convert_to_float)
    .cache()
    .prefetch(buffer_size=AUTOTUNE)
)


# Load pretrained model Xception
pretrained_model = tf.keras.applications.xception.Xception(
    include_top=False,
    weights='imagenet',
    input_shape=[128,128,3],
)
pretrained_model.trainable = False


model = keras.Sequential([
    # Preprocessing images
    pretrained_model,

    layers.GlobalAveragePooling2D(),

    layers.Dense(64, activation='relu'),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Dense(1, activation='sigmoid')
])

model.summary()


model.compile(optimizer = 'adam',
             loss='binary_crossentropy',
             metrics=['accuracy'])


history = model.fit(
    train_ds,
    validation_data=valid_ds,
    epochs=4,
    shuffle=True,
)


history_frame = pd.DataFrame(history.history)
history_frame.loc[:, ['loss', 'val_loss']].plot()
history_frame.loc[:, ['accuracy', 'val_accuracy']].plot();





model.save('../Models/model_autotune_test2.h5')



